# Architecture Documentation

## System Overview

Discover Project Skills is a five-phase analysis and generation system that transforms codebase inspection into actionable, contextual skills for Claude Code.

## Components

### 1. Skill File (`skills/discover-project-skills.md`)

**Purpose**: Main executable skill containing all analysis and generation logic.

**Sections**:
- Overview: What the skill does
- Phase 0-4: Workflow steps
- Error Handling: Recovery strategies
- After Generation: Cleanup and summary
- Key Principles: Design guidelines

### 2. Slash Command (`commands/discover-skills.md`)

**Purpose**: User-facing entry point that invokes the skill.

**Content**: Simple invocation command.

### 3. Generated Skills (`.claude/skills/*.md`)

**Purpose**: Output artifacts containing project-specific patterns.

**Types**:
- Technology skills (e.g., `postgresql-patterns.md`)
- Project skills (e.g., `api-layer-patterns.md`)

**Marker**: `<!-- Generated by discover-project-skills on YYYY-MM-DD -->`

## Data Flow

```
User runs /discover-skills
    ↓
Phase 0: Check existing skills
    ↓
Phase 1: Scan package files, detect technologies
    ↓
Phase 2: User selects areas to analyze
    ↓
Phase 3: Deep analysis of selected areas
    ↓
Phase 4: Generate skills from findings
    ↓
Commit generated skills to .claude/skills/
```

## Hybrid Scanning Strategy

### Decision Logic

```python
file_count = count_source_files()

if file_count < 50:
    use_direct_tools()  # Read, Glob, Grep
else:
    use_task_agents()   # Task/Explore
```

### Direct Tools Mode

**Tools**: Read, Glob, Grep
**Efficiency**: Low token usage
**Speed**: Fast for small projects
**Limit**: Doesn't scale to large codebases

### Agent Mode

**Tools**: Task with Explore subagent
**Efficiency**: Higher token usage, but isolated
**Speed**: Slower startup, efficient for large scans
**Limit**: None

## Chain Detection Algorithm

### Directory-Based Proxy

**Input**: Directory structure from Phase 1
**Output**: Skill relationship graph

**Algorithm**:
1. Identify layer directories:
   - `/api`, `/controllers` → API layer
   - `/service`, `/domain` → Service layer
   - `/repository`, `/dao` → Database layer
   - `/messaging`, `/events` → Messaging layer

2. Build typical flow chains:
   - API → Service → Database
   - API → Messaging
   - Event Consumer → Service → Database

3. Add "Related Skills" to each skill pointing to next layer

**Example**:
```
Directories: /controllers, /services, /repositories
Skills: rest-api, service-layer, postgresql-access
Chain: rest-api → service-layer → postgresql-access
```

## Token Budget Management

### Validation Process

```python
def validate_token_budget(skill_content):
    chars = len(skill_content)
    tokens = chars / 4  # Approximation

    if tokens > 500:
        skill_content = optimize(skill_content)
        tokens = len(skill_content) / 4

        if tokens > 500:
            warn_user_and_confirm()

    return skill_content
```

### Optimization Steps

1. Remove mermaid diagrams
2. Keep top 3-4 patterns only
3. Consolidate Key Files section
4. Remove redundant descriptions

## Skill Discovery Mechanism

### Dual Discovery Paths

**1. Explicit Chaining**:
- Each skill has "Related Skills" section
- Lists next skills in workflow
- Example: API skill → Service skill

**2. Context Matching**:
- Rich descriptions with keywords
- File patterns for location matching
- Scenarios for use case matching

### Description Template

```
<Technology> <what-it-does>. Use when <trigger-keywords>,
especially in <file-patterns>, or <scenarios>.
```

**Example**:
```
PostgreSQL database access patterns. Use when working with
database queries, SQL operations, repository pattern, especially
in src/repository/ or src/dao/ files, or implementing CRUD
operations and query optimization.
```

**Matching**:
- User mentions "database queries" → keyword match
- User edits file in `src/repository/` → file pattern match
- User says "implement CRUD" → scenario match

## Error Handling Strategy

### Principles

1. **Never fail silently**: Always inform user
2. **Graceful degradation**: Partial results > none
3. **Actionable feedback**: Suggest fixes
4. **Continue on error**: Skip failed skill, continue others

### Error Categories

**Phase 0**: Directory/permission errors
**Phase 1**: Missing package files, read errors
**Phase 2**: Invalid user input
**Phase 3**: Pattern detection failures
**Phase 4**: Write errors, token budget exceeded

Each has specific recovery strategy documented in skill file.

## Design Decisions

### Why Markdown Skills?

- Human-readable and editable
- Version control friendly
- YAML frontmatter for metadata
- Easy to import/share

### Why Directory-Based Chain Detection?

- No need for AST parsing (complex, language-specific)
- Fast and reliable
- Works across all languages
- Captures 90%+ of architectural patterns

### Why Token Budget of 500?

- Balance between detail and efficiency
- Keeps skills focused and scannable
- Prevents context window bloat
- Forces prioritization of key patterns

### Why Commit Generated Skills?

- Team sharing: Everyone gets same skills
- Version control: Track pattern evolution
- Portability: Import across projects
- Documentation: Skills serve as project docs

## Testing Strategy

### Test Targets

1. **Simple**: tradingview-mcp-server (Node/TypeScript MCP server)
2. **Complex**: gradle (Java/Kotlin/Groovy multi-module)

### Validation Points

- Technology detection accuracy
- Token budget compliance
- Skill chain correctness
- Description quality
- Contextual invocation
- Re-run capability

See `docs/testing-guide.md` for detailed procedures.

## Future Enhancements

### Planned

- Auto-detect when to re-run (git hooks)
- Incremental updates (only changed areas)
- Skill effectiveness metrics
- Cross-project skill library

### Considered

- AST parsing for exact call chains (complex, maybe later)
- ML-based pattern detection (overkill for v1)
- IDE integration (out of scope)
