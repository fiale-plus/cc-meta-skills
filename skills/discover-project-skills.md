---
name: discover-project-skills
description: Analyze codebase to discover technologies and project patterns, then generate contextual skills for both
---

# Discover Project Skills

## Overview

This skill analyzes your codebase to automatically discover:
1. **Technologies used**: Frameworks, databases, messaging systems, API protocols
2. **Project-specific patterns**: Architecture flows, module organization, design patterns
3. **Contextual skills**: Generates reusable skill files that chain together

**When to use:**
- Starting work on a new codebase
- After major architectural changes
- When onboarding to a project
- To document project patterns as skills

**Output:**
- Technology skills (e.g., `kafka-patterns.md`, `grpc-best-practices.md`)
- Project skills (e.g., `api-layer-patterns.md`, `service-layer-patterns.md`)
- Saved to `.claude/skills/` for automatic discovery

## Phase 0: Pre-check Existing Skills

**Before generating skills, check for existing generated skills:**

1. Check if `.claude/skills/` directory exists in current working directory
2. If exists, scan for files containing marker: `<!-- Generated by discover-project-skills -->`
3. Count existing generated skills

**If existing skills found:**
- Present to user: "Found N existing skills: [list names]"
- Ask using AskUserQuestion tool:
  ```
  Question: "How should I proceed with existing skills?"
  Options:
    - Regenerate All: Delete all existing generated skills and create fresh
    - Update Specific: Ask which areas to regenerate, keep others
    - Cancel: Exit without making changes
  ```

**If .claude/skills/ doesn't exist:**
- Create directory: `mkdir -p .claude/skills`
- Inform user: "Created .claude/skills/ directory for generated skills"

**Error handling:**
- Cannot create directory → Suggest alternative location or check permissions
- Cannot read existing skills → Warn user, offer to continue without checking

## Phase 1: Quick Technology Scan

**Goal**: Quickly identify major technologies without deep analysis.

### Hybrid Scanning Strategy

**Estimate project size first:**
```bash
find . -type f \( -name "*.ts" -o -name "*.js" -o -name "*.java" -o -name "*.kt" -o -name "*.py" -o -name "*.go" \) | wc -l
```

**Choose scanning method:**
- **< 50 files**: Use Read/Glob/Grep tools directly
- **>= 50 files**: Use Task tool with Explore subagent

### Package Files to Scan

**Node.js:**
- Read `package.json` if exists
- Check dependencies for:
  - TypeScript: `typescript` in devDependencies or `tsconfig.json` exists
  - Express: `express` in dependencies
  - NestJS: `@nestjs/core` in dependencies
  - MongoDB: `mongodb`, `mongoose` in dependencies
  - PostgreSQL: `pg`, `typeorm`, `prisma` in dependencies
  - gRPC: `@grpc/grpc-js`, `@grpc/proto-loader` in dependencies
  - GraphQL: `graphql`, `apollo-server`, `@nestjs/graphql` in dependencies

**Java/Kotlin:**
- Read `pom.xml`, `build.gradle`, or `build.gradle.kts` if exists
- Check for:
  - Kotlin: `build.gradle.kts` file or `kotlin-stdlib` dependency
  - Ktor: `io.ktor:ktor-server-*` dependencies
  - Spring Boot: `spring-boot-starter-*` dependencies
  - Kafka: `kafka-clients`, `spring-kafka` dependencies
  - PostgreSQL: `postgresql` JDBC driver
  - MongoDB: `mongodb-driver`, `spring-data-mongodb`
  - gRPC: `grpc-*`, `protobuf-java` dependencies
  - GraphQL: `graphql-java`, `spring-boot-starter-graphql`

**Python:**
- Read `requirements.txt` or `pyproject.toml` if exists
- Check for:
  - FastAPI: `fastapi`
  - PostgreSQL: `psycopg2`, `asyncpg`
  - MongoDB: `pymongo`, `motor`
  - GraphQL: `graphene`, `strawberry-graphql`, `ariadne`

**Go:**
- Read `go.mod` if exists
- Check for:
  - gRPC: `google.golang.org/grpc`
  - Kafka: `github.com/segmentio/kafka-go`, `github.com/Shopify/sarama`
  - PostgreSQL: `github.com/lib/pq`, `gorm.io/driver/postgres`
  - MongoDB: `go.mongodb.org/mongo-driver`

### REST API Detection

Look for HTTP method annotations/decorators in code:
- **Node**: `app.get()`, `app.post()`, `@Get()`, `@Post()` decorators
- **Java/Kotlin**: `@RestController`, `@GetMapping`, `@PostMapping`, `@PutMapping`, `@DeleteMapping`
- **Python**: `@app.get`, `@app.post`, `@route` decorators

### Directory Structure Scan

Scan top 2 directory levels for these patterns:
- `/api`, `/controllers`, `/handlers`, `/routes` → API layer
- `/service`, `/domain`, `/business` → Service layer
- `/repository`, `/dao`, `/data` → Database access layer
- `/messaging`, `/events`, `/kafka` → Messaging patterns
- `/grpc`, `/proto` → gRPC usage
- `/graphql`, `/schema` → GraphQL usage

### Present Findings

Group discoveries by category:
```markdown
**Detected Technologies:**

Languages: TypeScript, Java
Frameworks: Express, Spring Boot
Databases: PostgreSQL, MongoDB
Messaging: Kafka
API Protocols: REST, gRPC
```

**Error handling:**
- No package files found → Ask user to point to key files manually
- File read errors → Skip that file, continue with others
- No technologies detected → Present findings anyway, ask user for hints

## Phase 2: Focus Selection

**Goal**: Let user choose which areas to analyze deeply.

**Present findings from Phase 1 grouped by category:**
```markdown
I found the following technologies and patterns:

**API Layer**: REST endpoints in /controllers
**Service Layer**: Business logic in /services
**Database**: PostgreSQL access via /repositories
**Messaging**: Kafka producers/consumers in /events

Which areas should I analyze deeper?
```

**Use AskUserQuestion tool with options:**
- API Layer Patterns
- Service Layer Patterns
- Database Access Patterns
- Messaging Patterns
- Module Architecture
- All (medium depth across all)
- Other (let user specify)

**Adaptive depth strategy:**
- 1-2 areas selected → Deep dive with file examples and pattern extraction
- "All" selected → Medium depth across all areas
- Track selected areas to avoid duplicate work in Phase 3

**Error handling:**
- User selects invalid option → Re-prompt with valid options
- No areas selected → Ask if they want to cancel

## Phase 3: Deep Analysis

**Goal**: Extract patterns, flows, and examples from selected areas.

**For each selected area:**

### Module/System Analysis

1. **Identify entry points:**
   - Controllers (REST), handlers (events), main packages
   - Use Glob to find: `**/*Controller.ts`, `**/*Handler.java`, etc.

2. **Find key abstractions:**
   - Interfaces, base classes, common utilities
   - Use Grep to search for: `interface`, `abstract class`, `extends`

3. **Map directory structure:**
   - Note naming conventions (PascalCase, camelCase, snake_case)
   - Identify module boundaries

4. **Detect dependencies:**
   - Which modules depend on which (based on directory structure)

### Flow Analysis

**For synchronous flows (REST APIs):**
1. Pick 2-3 representative endpoints
2. Note the pattern: Controller → Service → Repository → Database
3. Document error handling approach (try/catch, Result types, exceptions)
4. Note validation patterns

**For asynchronous flows (Events):**
1. Find event producers (where events are published)
2. Find event consumers (where events are processed)
3. Document message structure
4. Note retry/failure handling

### Pattern Extraction

Look for:
- **Design patterns**: Repository pattern, Service layer, Factory, Strategy
- **Architectural style**: Layered, hexagonal, event-driven, CQRS
- **Testing approaches**: Unit tests, integration tests, test utilities
- **Common utilities**: Logging, metrics, error handling helpers

### Chain Detection (Directory-Based Proxy)

**Build skill relationship graph based on directories:**

If directories exist:
- `/api` + `/service` + `/repository` → Chain: `api-patterns` → `service-layer-patterns` → `database-access-patterns`
- `/api` + `/messaging` → Chain: `api-patterns` → `messaging-patterns`
- `/events/producers` + `/events/consumers` → Chain: `event-producer-patterns` → `event-consumer-patterns`

**Store findings for Phase 4:**
- File paths with line numbers for examples
- Pattern names and descriptions
- Skill chain relationships

**Error handling:**
- Selected area has no patterns → Notify user, ask to skip or provide hints
- File references invalid → Validate before including, skip if invalid
- Analysis timeout → Fall back to shallow analysis, notify user

## Phase 4: Skill Generation

**Goal**: Generate skill files from analysis findings.

### When to Generate Skills

**Technology Skills:**
Generate when technology is detected AND has 2+ file examples.
Examples: `postgresql-patterns.md`, `kafka-patterns.md`, `grpc-patterns.md`

**Project Skills:**
Generate when architectural layer is detected AND has clear patterns.
Examples: `api-layer-patterns.md`, `service-layer-patterns.md`, `event-processing-patterns.md`

### Technology Skill Template

```markdown
<!-- Generated by discover-project-skills on YYYY-MM-DD -->
---
name: <technology>-patterns
description: <Technology> <what-it-does>. Use when <trigger-keywords>, especially in <file-patterns>, or <scenarios>.
---

# <Technology> Patterns

## Overview
[How this technology is used in this codebase - 2-3 sentences]

## Key Patterns
- **Pattern 1**: [Description]
  - Example: `path/to/file.ext:123`
- **Pattern 2**: [Description]
  - Example: `path/to/another.ext:456`

## Common Gotchas
- [What to watch for - based on code inspection]
- [Common mistake to avoid]

## Related Skills
When working with <technology>, also consider:
- `related-skill-1` - [When to use]
- `related-skill-2` - [When to use]

## Key Files
- `path/to/config:line` - [Configuration]
- `path/to/example:line` - [Reference implementation]
```

### Project Skill Template

```markdown
<!-- Generated by discover-project-skills on YYYY-MM-DD -->
---
name: <subsystem>-<aspect>
description: <Subsystem> <aspect> <what-it-does>. Use when <trigger-keywords>, especially in <file-patterns>, or <scenarios>.
---

# <Subsystem> <Aspect>

## Architecture
[Text description of architecture - 3-4 sentences]

## Key Components
- **Component 1** (`path/to/component`): [Purpose and responsibility]
- **Component 2** (`path/to/component`): [Purpose and responsibility]

## Flows

### Synchronous Flow
1. [Step 1 - what happens]
2. [Step 2 - what happens]
3. [Step 3 - what happens]

### Asynchronous Flow
1. [Event trigger]
2. [Processing steps]
3. [Side effects]

## Error Handling
[How errors are handled in this subsystem]

## Testing Strategy
[How this subsystem is tested]

## Related Skills
This subsystem typically interacts with:
- `related-skill-1` - [For X functionality]
- `related-skill-2` - [For Y functionality]

## Key Files
- `path/to/file:line` - [Purpose]
- `path/to/file:line` - [Purpose]
```

### Description Template Requirements

Every description MUST include all four elements:
1. **Technology/Pattern name**: "PostgreSQL database access patterns"
2. **What it does**: "database queries and ORM usage"
3. **Trigger keywords**: "database, SQL, queries, repository pattern"
4. **File patterns**: "src/repository/, src/dao/, *.repository.ts"
5. **Scenarios**: "implementing CRUD operations, optimizing queries"

**Example:**
```markdown
description: PostgreSQL database access patterns. Use when working with database queries, SQL operations, repository pattern, especially in src/repository/ or src/dao/ files, or implementing CRUD operations and query optimization.
```
